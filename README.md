# üáßüá∑ Projeto Delegacia 5.0: Chatbot Humanizado para PCPE

## üéØ Vis√£o Geral do Projeto

Este projeto consiste no desenvolvimento e implementa√ß√£o de um **Assistente Virtual H√≠brido** para a Pol√≠cia Civil de Pernambuco (PCPE). O objetivo √© modernizar o atendimento, fornecendo informa√ß√µes instant√¢neas sobre servi√ßos, legisla√ß√£o e procedimentos, reduzindo a sobrecarga nas delegacias presenciais.

O sistema atende integralmente ao requisito de **Conformidade com a LGPD** e √† prefer√™ncia por **Tecnologias Open Source** (Ollama/FAISS) em conjunto com uma solu√ß√£o **Cloud-Native** (Gemini API) para garantir estabilidade e alta performance.

## ‚öôÔ∏è Arquitetura do Sistema (Hybrid RAG)

O projeto utiliza uma arquitetura de Gera√ß√£o Aumentada por Recupera√ß√£o (RAG) para garantir que as respostas sobre leis e procedimentos sejam factuais e baseadas **apenas** na base de conhecimento oficial (os arquivos `.txt` na pasta `docs`).

| Componente | Fun√ß√£o | Tecnologia Espec√≠fica |
| :--- | :--- | :--- |
| **Orquestra√ß√£o** | Gerencia o fluxo de conversa e a conex√£o com canais externos (Telegram/WhatsApp). | **n8n** (Docker) |
| **C√©rebro (LLM)** | Gera a resposta final, com alta velocidade e intelig√™ncia. | **Google Gemini 2.0 Flash** (API Cloud) |
| **Mem√≥ria (Vector DB)** | Armazena a Lei 7550/77 e os procedimentos em formato vetorial. | **FAISS** (√≠ndice) |
| **Embeddings** | Transforma texto em vetores para busca sem√¢ntica. | **Ollama** (`nomic-embed-text` local) |

## ‚úÖ Requisitos de Execu√ß√£o

Para rodar o projeto em um novo ambiente, √© necess√°rio ter instalado e configurado:

1.  **Python 3.11** (com ambiente virtual `venv` ativado).
2.  **Docker Desktop** (para rodar o n8n de forma isolada).
3.  **Ollama CLI** (para gerenciar os modelos de embeddings locais).
4.  **ngrok** (para criar o t√∫nel HTTPS p√∫blico para o Telegram).
5.  **Chave Gemini API** (Definida como vari√°vel de ambiente `GEMINI_API_KEY`).
6.  **Token do Bot do Telegram** (Obtido via @BotFather).

## üöÄ Guia de Setup e Execu√ß√£o (Passo a Passo)

Siga este guia em 4 passos. Certifique-se de estar na pasta raiz do projeto com o `venv` ativado.

### 1. Prepara√ß√£o da Base de Conhecimento e Vari√°veis

1.  **Defina sua Chave Gemini:**
    ```bash
    $env:GEMINI_API_KEY="SUA_CHAVE_AQUI"
    ```
2.  **Instale as Depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```
3.  **Baixe os Modelos Ollama (Embeddings):**
    ```bash
    ollama pull nomic-embed-text
    ```
4.  **Limpe o Cache:** Garanta que a base vetorial seja recriada com os arquivos `.txt` novos.
    ```bash
    rm -rf faiss_index
    ```

### 2. Inicie a API Python (O C√©rebro)

Mantenha esta janela do terminal rodando o tempo todo. Ele ir√° ler os arquivos `.txt` e criar a mem√≥ria FAISS:
```bash
uvicorn api:app --reload